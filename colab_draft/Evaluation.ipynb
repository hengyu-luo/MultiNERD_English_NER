{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/RISE_Assignment/*  /content/"
      ],
      "metadata": {
        "id": "oRmoGjkXt7y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMRS6ZF2jAa_"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers[torch]\n",
        "!pip install wandb\n",
        "!pip install seqeval\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python data_preparation.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjiQADC7jPnj",
        "outputId": "05ba693c-d921-482b-948c-0065b6eeea0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer_config.json: 100% 29.0/29.0 [00:00<00:00, 162kB/s]\n",
            "vocab.txt: 100% 213k/213k [00:00<00:00, 1.81MB/s]\n",
            "tokenizer.json: 100% 436k/436k [00:00<00:00, 3.57MB/s]\n",
            "config.json: 100% 570/570 [00:00<00:00, 1.48MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval.py --model_path /content/results_system_a/checkpoint-13128 --data_path ./tokenized_dataset_a --system a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Th16hVPmumK",
        "outputId": "2153f902-d1db-4184-f2ff-6394d1a9feeb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-04 07:08:06.051297: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-04 07:08:06.051347: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-04 07:08:06.051375: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-04 07:08:07.233887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-ANIM', 'I-ANIM', 'B-BIO', 'I-BIO', 'B-CEL', 'I-CEL', 'B-DIS', 'I-DIS', 'B-EVE', 'I-EVE', 'B-FOOD', 'I-FOOD', 'B-INST', 'I-INST', 'B-MEDIA', 'I-MEDIA', 'B-MYTH', 'I-MYTH', 'B-PLANT', 'I-PLANT', 'B-TIME', 'I-TIME', 'B-VEHI', 'I-VEHI']\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100% 4113/4114 [06:26<00:00,  9.01it/s]/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "100% 4114/4114 [06:55<00:00,  9.91it/s]\n",
            "Evaluation Results: {'eval_loss': 0.045835480093955994, 'eval_precision': 0.9105119187182493, 'eval_recall': 0.9085591733281342, 'eval_f1': 0.909534497901825, 'eval_accuracy': 0.9849751458828615, 'eval_runtime': 408.8172, 'eval_samples_per_second': 80.496, 'eval_steps_per_second': 10.063}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/accuracy ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               eval/loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/precision ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/recall ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval/samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/global_step ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/accuracy 0.98498\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/f1 0.90953\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               eval/loss 0.04584\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/precision 0.91051\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/recall 0.90856\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/runtime 408.8172\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval/samples_per_second 80.496\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/steps_per_second 10.063\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/global_step 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20231204_071508-esidzmcj\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231204_071508-esidzmcj/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval.py --model_path /content/results_system_b/checkpoint-26256 --data_path ./tokenized_dataset_b --system b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Hn9n9MCi2Ma",
        "outputId": "ee4f9e54-d223-4906-b705-079747dc20fe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-04 07:15:32.374967: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-04 07:15:32.375022: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-04 07:15:32.375048: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-04 07:15:33.512840: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-ANIM', 'I-ANIM', 'B-DIS', 'I-DIS']\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100% 4114/4114 [06:00<00:00, 11.45it/s]\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "100% 4114/4114 [06:14<00:00, 10.98it/s]\n",
            "Evaluation Results: {'eval_loss': 0.029805470257997513, 'eval_precision': 0.9447016685594479, 'eval_recall': 0.9419450372370541, 'eval_f1': 0.9433213390033803, 'eval_accuracy': 0.9909891218211945, 'eval_runtime': 370.0116, 'eval_samples_per_second': 88.938, 'eval_steps_per_second': 11.119}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/accuracy ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               eval/loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/precision ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/recall ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval/samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/global_step ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/accuracy 0.99099\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/f1 0.94332\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               eval/loss 0.02981\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/precision 0.9447\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/recall 0.94195\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/runtime 370.0116\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval/samples_per_second 88.938\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/steps_per_second 11.119\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/global_step 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20231204_072155-sx9m9us8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231204_072155-sx9m9us8/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python traineval.py --system a"
      ],
      "metadata": {
        "id": "QxjGBclawzUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72b05d15-c2c4-4c2f-8162-b8811b4617b7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-04 07:24:04.676581: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-04 07:24:04.676635: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-04 07:24:04.676666: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-04 07:24:05.905822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "  0% 0/4 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            " 25% 1/4 [00:00<00:01,  2.40it/s]\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                 \n",
            "\u001b[A{'eval_loss': 3.1261680126190186, 'eval_precision': 0.0425531914893617, 'eval_recall': 0.3333333333333333, 'eval_f1': 0.07547169811320754, 'eval_accuracy': 0.2676056338028169, 'eval_runtime': 0.0572, 'eval_samples_per_second': 52.47, 'eval_steps_per_second': 34.98, 'epoch': 1.0}\n",
            " 50% 2/4 [00:00<00:00,  2.40it/s]\n",
            "100% 2/2 [00:00<00:00, 72.69it/s]\u001b[A\n",
            " 75% 3/4 [00:02<00:00,  1.10it/s]\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                 \n",
            "\u001b[A{'eval_loss': 3.0270802974700928, 'eval_precision': 0.025, 'eval_recall': 0.16666666666666666, 'eval_f1': 0.04347826086956522, 'eval_accuracy': 0.36619718309859156, 'eval_runtime': 0.0498, 'eval_samples_per_second': 60.181, 'eval_steps_per_second': 40.121, 'epoch': 2.0}\n",
            "100% 4/4 [00:02<00:00,  1.10it/s]\n",
            "100% 2/2 [00:00<00:00, 90.22it/s]\u001b[A\n",
            "{'train_runtime': 11.5301, 'train_samples_per_second': 0.52, 'train_steps_per_second': 0.347, 'train_loss': 3.116750717163086, 'epoch': 2.0}\n",
            "100% 4/4 [00:06<00:00,  1.50s/it]\n",
            "  0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100% 2/2 [00:00<00:00, 66.04it/s]\n",
            "Evaluation Results for system_a: {'eval_loss': 3.1817753314971924, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.25, 'eval_runtime': 0.0626, 'eval_samples_per_second': 47.943, 'eval_steps_per_second': 31.962, 'epoch': 2.0}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy ▂█▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        eval/f1 █▅▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ▅▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/precision █▅▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/recall █▅▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▅▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▄█▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▄█▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        eval/f1 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 3.18178\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/precision 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/recall 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 0.0626\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 47.943\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 31.962\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 2.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1568191592448.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 3.11675\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 11.5301\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 0.52\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.347\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20231204_072419-vg15nle4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231204_072419-vg15nle4/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g2lMAj_DtLn0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}